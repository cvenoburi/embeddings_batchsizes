{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.0\n",
      "Torchvision Version:  0.4.1a0+d94043a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import torch\n",
    "import torchsummary\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import mytorch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu:  cuda\n"
     ]
    }
   ],
   "source": [
    "use_gpu = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(use_gpu)\n",
    "print(\"Using gpu: \", use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGNET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMGNET_STD = [0.229, 0.224, 0.225]\n",
    "img_dir = ''\n",
    "inp_csv = 'file_lists/images_list_short2.val'\n",
    "sep = '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200\n"
     ]
    }
   ],
   "source": [
    "with open(inp_csv,'r') as f:\n",
    "    img_lst = pd.read_csv(f,header=None,sep=sep)\n",
    "print(\"Number of images: {}\".format(len(img_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the  model\n",
    "# print(\"Loading the model ...\")\n",
    "# img_dim = (3, 224, 224)\n",
    "# model = torchvision.models.alexnet(pretrained=True)\n",
    "# model.to(device)\n",
    "# print(model)\n",
    "# new_classifier = torch.nn.Sequential(*list(model.classifier.children())[:-2])\n",
    "# model.classifier = new_classifier\n",
    "# print(torchsummary.summary(model, img_dim))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.71\n",
      "Params size (MB): 512.16\n",
      "Estimated Total Size (MB): 731.45\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the  model\n",
    "print(\"Loading the model ...\")\n",
    "img_dim = (3, 224, 224)\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.to(device)\n",
    "print(model)\n",
    "new_classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])\n",
    "model.classifier = new_classifier\n",
    "print(torchsummary.summary(model, img_dim))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200\n"
     ]
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_dim[1:]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMGNET_MEAN, std=IMGNET_STD)\n",
    "    ])\n",
    "\n",
    "test_images = mytorch_utils.MyDataset(inp_csv, sep, img_dir, test_transforms)\n",
    "print(\"Number of images: {}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "dataloader20 = torch.utils.data.DataLoader(test_images, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "\n",
    "embeddings20 = []\n",
    "embeddings20t = []\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(dataloader20):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(outputs.size(0), -1)\n",
    "        embeddings20.extend(outputs.data.cpu().numpy())\n",
    "        embeddings20t.extend(outputs)\n",
    "print(len(embeddings20),len(embeddings20t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "dataloader50 = torch.utils.data.DataLoader(test_images, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "\n",
    "embeddings50 = []\n",
    "embeddings50t = []\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(dataloader50):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(outputs.size(0), -1)\n",
    "        embeddings50.extend(outputs.data.cpu().numpy())\n",
    "        embeddings50t.extend(outputs)\n",
    "print(len(embeddings50),len(embeddings50t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "batch_size = 180\n",
    "dataloader180 = torch.utils.data.DataLoader(test_images, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "\n",
    "embeddings180 = []\n",
    "embeddings180t = []\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(dataloader180):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(outputs.size(0), -1)\n",
    "        embeddings180.extend(outputs.data.cpu().numpy())\n",
    "        embeddings180t.extend(outputs)\n",
    "print(len(embeddings180),len(embeddings180t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just get an image to test\n",
    "i = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# note that 'i' and 'i+100' are the same image, i.e., tensors are the same\n",
    "print(torch.all(torch.eq(test_images[i][0],test_images[i+100][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 vs 50: False\n",
      "20 vs 180: False\n",
      "50 vs 180: False\n"
     ]
    }
   ],
   "source": [
    "# check if the resulting feature tensors are the same\n",
    "print(\"20 vs 50: {}\".format(torch.all(torch.eq(embeddings20t[i],embeddings50t[i]))))\n",
    "print(\"20 vs 180: {}\".format(torch.all(torch.eq(embeddings20t[i],embeddings180t[i]))))\n",
    "print(\"50 vs 180: {}\".format(torch.all(torch.eq(embeddings50t[i],embeddings180t[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20[i] vs 20[i+100]: True\n",
      "50[i] vs 50[i+100]: True\n",
      "180[i] vs 180[i+100]: False\n",
      "20[i] vs 180[i+100]: True\n"
     ]
    }
   ],
   "source": [
    "# check if the feature tensors are the same for the recurrence of the same image\n",
    "print(\"20[i] vs 20[i+100]: {}\".format(torch.all(torch.eq(embeddings20t[i],embeddings20t[i+100]))))\n",
    "print(\"50[i] vs 50[i+100]: {}\".format(torch.all(torch.eq(embeddings50t[i],embeddings50t[i+100]))))\n",
    "print(\"180[i] vs 180[i+100]: {}\".format(torch.all(torch.eq(embeddings180t[i],embeddings180t[i+100]))))\n",
    "print(\"20[i] vs 180[i+100]: {}\".format(torch.all(torch.eq(embeddings20t[i],embeddings180t[i+100]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.970957   -1.5108874  -1.805858   ... -0.9411883   0.06945309\n",
      "  -1.0025449 ]]\n",
      "[[-0.9709627  -1.5108864  -1.8058552  ... -0.9411878   0.06945163\n",
      "  -1.0025436 ]]\n",
      "[[-0.9709636  -1.5108848  -1.8058562  ... -0.9411872   0.06945243\n",
      "  -1.002543  ]]\n"
     ]
    }
   ],
   "source": [
    "v1 = embeddings20[i].reshape(1,-1)\n",
    "v2 = embeddings50[i].reshape(1,-1)\n",
    "v3 = embeddings180[i].reshape(1,-1)\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.00015021624858491123\n",
      "Cosine: 0.00000000000000000000\n",
      "Manhattan: 0.00753203220665454865\n"
     ]
    }
   ],
   "source": [
    "# just compare v1 and v2\n",
    "print(\"Euclidean: {:.20f}\".format(distance.euclidean(v1,v2)))\n",
    "print(\"Cosine: {:.20f}\".format(distance.cosine(v1,v2)))\n",
    "print(\"Manhattan: {:.20f}\".format(distance.cityblock(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.00000000000000000000\n",
      "Cosine: 0.00000000000000000000\n",
      "Manhattan: 0.00000000000000000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "v1 = embeddings20[i].reshape(1,-1)\n",
    "v2 = embeddings20[i+100].reshape(1,-1)\n",
    "print(\"Euclidean: {:.20f}\".format(distance.euclidean(v1,v2)))\n",
    "print(\"Cosine: {:.20f}\".format(distance.cosine(v1,v2)))\n",
    "print(\"Manhattan: {:.20f}\".format(distance.cityblock(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.00000000000000000000\n",
      "Cosine: 0.00000000000000000000\n",
      "Manhattan: 0.00000000000000000000\n"
     ]
    }
   ],
   "source": [
    "v1 = embeddings50[i].reshape(1,-1)\n",
    "v2 = embeddings50[i+100].reshape(1,-1)\n",
    "print(\"Euclidean: {:.20f}\".format(distance.euclidean(v1,v2)))\n",
    "print(\"Cosine: {:.20f}\".format(distance.cosine(v1,v2)))\n",
    "print(\"Manhattan: {:.20f}\".format(distance.cityblock(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.00016844496713019907\n",
      "Cosine: -0.00000011920928955078\n",
      "Manhattan: 0.00851609837263822556\n"
     ]
    }
   ],
   "source": [
    "v1 = embeddings180[i].reshape(1,-1)\n",
    "v2 = embeddings180[i+100].reshape(1,-1)\n",
    "print(\"Euclidean: {:.20f}\".format(distance.euclidean(v1,v2)))\n",
    "print(\"Cosine: {:.20f}\".format(distance.cosine(v1,v2)))\n",
    "print(\"Manhattan: {:.20f}\".format(distance.cityblock(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean: 0.00000000000000000000\n",
      "Cosine: 0.00000000000000000000\n",
      "Manhattan: 0.00000000000000000000\n"
     ]
    }
   ],
   "source": [
    "v1 = embeddings20[i].reshape(1,-1)\n",
    "v2 = embeddings180[i+100].reshape(1,-1)\n",
    "print(\"Euclidean: {:.20f}\".format(distance.euclidean(v1,v2)))\n",
    "print(\"Cosine: {:.20f}\".format(distance.cosine(v1,v2)))\n",
    "print(\"Manhattan: {:.20f}\".format(distance.cityblock(v1,v2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pth13_py37)",
   "language": "python",
   "name": "pth13_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
